---
title: "Kalpa_Batch30_SVM_Regression_Random_Forest"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Clear the environment

```{r}
rm(list=ls(all=TRUE))

```
# Load required libraries

```{r}
library(vegan)
library(dummies)
library(e1071)
library(DMwR)
```

#Set working Directory

```{r}
setwd("C:/insofe\\day23_svm\\assignment-svm-random-forest-kalpa-subbaiah-master")
```

# Load the data

```{r}
attr = c('price','lotSize','age','landValue','livingArea','pctCollege','bedrooms','fireplaces','bathrooms','rooms','heating', 'fuel', 'sewer', 'waterfront', 'newConstruction', 'centralAir')

# Read the data using csv file
data_House = read.csv(file = "SaratogaHouses.csv", 
                header = TRUE, col.names = attr)

# Convert attribute to appropriate type  
cat_Attr = c("heating", "fuel", "sewer", "waterfront", "newConstruction", "centralAir")
num_Attr = setdiff(attr, cat_Attr)
num_Attr = setdiff(num_Attr, "price")
rm(attr)


cat_Data <- data.frame(data_House[,cat_Attr])
num_Data <- data.frame(sapply(data_House[,num_Attr], as.numeric))

data = cbind(num_Data, cat_Data)
rm(cat_Data, num_Data)

# Do the summary statistics and check for missing values and outliers.
summary(data)
str(data)
```
# Data Preprocessing

```{r}
ind_Num_Attr = num_Attr
rm(num_Attr)
ind_Cat_Attr = cat_Attr
rm(cat_Attr)
```
# Standardizing the numeric data
```{r}
cla_Data = decostand(data[,ind_Num_Attr], "range") 
rm(ind_Num_Attr)
```

# Convert all categorical attributes to numeric 
# 1. Using dummy function
```{r}
heating = dummy(data$heating)
fuel = dummy(data$fuel)
sewer = dummy(data$sewer)
waterfront = dummy(data$waterfront)
newConstruction = dummy(data$newConstruction)
CentralAir = dummy(data$centralAir)
cla_Data = cbind(cla_Data, heating, fuel,sewer,waterfront,newConstruction,CentralAir)
str(cla_Data)
ind_Attr = names(cla_Data)

# Append the Target attribute 
cla_Data = cbind(cla_Data, price=data_House$price) 

str(cla_Data)
summary(cla_Data)
```
# Divide the data into test and train

```{r}
set.seed(123)

train_RowIDs = sample(1:nrow(cla_Data), nrow(cla_Data)*0.6)
train_Data = cla_Data[train_RowIDs,]
test_Data = cla_Data[-train_RowIDs,]
rm(train_RowIDs)
```
# Build best SVM model 

```{r}
model = svm(x = train_Data[,ind_Attr], 
            y = train_Data$price, 
            type = "nu-regression", 
            kernel = "linear", cost = 1e-7) 

# Look at the model summary
summary(model)
```
# Predict the model on train and test

```{r}
# Predict on train data and check the performance
regr.eval(train_Data$price, predict(model, train_Data[,ind_Attr]))

# Predict on test data and check the performance  
regr.eval(test_Data$price, predict(model, train_Data[,ind_Attr]))

rm(model)

# Hyperparameter tuning 
tuned <- tune.svm(x = train_Data[,ind_Attr], 
                  y = train_Data$price, 
                  type = "nu-regression", 
                  gamma = 10^(-6:-1), cost = 10^(1:2))
summary(tuned)

rm(test_Data, train_Data, tuned)
```
# ####################Part B ###################################################
#Clear the data
```{r}
rm(list = ls(all = T))
```
# Load required libraries

```{r}
library(DMwR)
library(randomForest)
library(caret)
library(inTrees)
```
# Load the data

```{r}
attr = c('price','lotSize','age','landValue','livingArea','pctCollege','bedrooms','fireplaces','bathrooms','rooms','heating', 'fuel', 'sewer', 'waterfront', 'newConstruction', 'centralAir')

# Read the data using csv file
data_House = read.csv(file = "SaratogaHouses.csv", 
                      header = TRUE, col.names = attr)
```

# Data Pre-Processing

```{r}
str(data_House)
summary(data_House)

table(data_House$price)
str(data_House$price) 

# seperate categorical and numerical values
cat_Attr = c("heating", "fuel", "sewer", "waterfront", "newConstruction", "centralAir")
num_Attr = setdiff(attr, cat_Attr)

# Seperate numerical and categorical variables and convert them into appropriate type
#data = data.frame(sapply(data, as.character))
cat_Data = data.frame(data_House[,cat_Attr])
num_Data = data.frame(sapply(data_House[,num_Attr], as.numeric))
data = cbind(num_Data, cat_Data)
rm(num_Attr, cat_Attr)

rm(cat_Data, num_Data)

# Handle missing values using knn imputation
sum(is.na(data))

#data = knnImputation(data = data, k = 5)
#sum(is.na(data))

summary(data)
str(data)

```
#Split dataset into train and test

```{r}
set.seed(123)

train_RowIDs = createDataPartition(data$price,p=0.7,list = FALSE)
train_Data = data[train_RowIDs,]
test_Data = data[-train_RowIDs,]
rm(train_RowIDs)
rm(data)
```
#Build the Regression model using randomForest

```{r}
model = randomForest(price ~ ., data=train_Data, 
                     keep.forest=TRUE, ntree=50) 

# Print and understand the model
print(model)

# Important attributes
model$importance  
round(importance(model), 2)   

# Extract and store important variables obtained from the random forest model
rf_Imp_Attr = data.frame(model$importance)
rf_Imp_Attr = data.frame(row.names(rf_Imp_Attr),rf_Imp_Attr[,1])
colnames(rf_Imp_Attr) = c('Attributes', 'Importance')
rf_Imp_Attr = rf_Imp_Attr[order(rf_Imp_Attr$Importance, decreasing = TRUE),]
rf_Imp_Attr
# plot (directly prints the important attributes) 
varImpPlot(model)

```
# Predict on train and test

```{r}
# Predict on Train data 
pred_Train = predict(model, 
                     train_Data[,setdiff(names(train_Data), "price")],
                     type="response", 
                     norm.votes=TRUE)

# Predict on train data and check the performance
reg_mod_train=regr.eval(train_Data$price, predict(model, train_Data[,setdiff(names(train_Data), "price")]))

# Predict on test data and check the performance  
reg_mod_test=regr.eval(test_Data$price, predict(model, train_Data[,setdiff(names(test_Data), "price")]))

```
#Build randorm forest using top 9 important attributes. 

```{r}
top_Imp_Attr = as.character(rf_Imp_Attr$Attributes[1:9])

# Build the Regression model using randomForest
model_Imp = randomForest(price~.,
                         data=train_Data[,c(top_Imp_Attr,"price")], 
                         keep.forest=TRUE,ntree=50) 

# Print and understand the model
print(model_Imp)

# Important attributes
model_Imp$importance
```
# Predict on Train and test

```{r}
# Predict on train data and check the performance
reg_mod_imp_train=regr.eval(train_Data$price, predict(model_Imp, train_Data[,setdiff(names(train_Data), "price")]))

# Predict on test data and check the performance  
reg_mod_imp_test=regr.eval(test_Data$price, predict(model_Imp, train_Data[,setdiff(names(test_Data), "price")]))

reg_mod_train
reg_mod_test
reg_mod_imp_train
reg_mod_imp_test
```
# Tune the model
```{r}
top_Imp_Attr = as.character(rf_Imp_Attr$Attributes[1:9])
set.seed(123)
x <- train_Data[,!(names(train_Data) %in% c("price"))]
y <- train_Data[,(names(train_Data) %in% c("price"))]
str(y)
tunedmodel <-tuneRF(x,y,ntreeTry = 50,trace=TRUE,plot=TRUE,doBest = TRUE)
print(tunedmodel)
tunedmodel$importance
varImpPlot(tunedmodel)
```
# Load required libraries

```{r}
# Predict on train data and check the performance
reg_tune_mod_train=regr.eval(train_Data$price, predict(tunedmodel, train_Data[,setdiff(names(train_Data), "price")]))

# Predict on test data and check the performance  
reg_tune_mod_test=regr.eval(test_Data$price, predict(tunedmodel, train_Data[,setdiff(names(test_Data), "price")]))

reg_tune_mod_train
reg_tune_mod_test
```
# Compare all the models

```{r}
reg_mod_train
reg_mod_test
reg_mod_imp_train
reg_mod_imp_test
reg_tune_mod_train
reg_tune_mod_test
```
